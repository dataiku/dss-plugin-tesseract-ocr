{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataiku\n",
    "from dataiku import pandasutils as pdu\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "try:\n",
    "    from PIL import Image\n",
    "    from io import BytesIO\n",
    "    import pytesseract\n",
    "    import re\n",
    "    import math\n",
    "    import cv2\n",
    "    import matplotlib.pyplot as plt\n",
    "except Exception as e:\n",
    "    raise Exception(\"Be sure to set the right code env. {}\".format(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set folder id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You must enter manually your input folder id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter manually your input folder id (can be found in the folder URL)\n",
    "input_folder_id = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some image processing functions\n",
    "Here are the defintion of some image processing functions, you can add more functions and/or modify the existing ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# noise removal\n",
    "def blurring(image):\n",
    "    return cv2.medianBlur(image,5)\n",
    " \n",
    "# thresholding\n",
    "def thresholding(image):\n",
    "    return cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "# resizing\n",
    "def resizing(image):\n",
    "    return cv2.resize(image, None, fx=1.5, fy=1.5, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "# extract a rectangle from the image starting at (x, y) and ending at (x+width, y+height)\n",
    "def cropping(image, x, y, width, height):\n",
    "    return image[y:y+height, x:x+width]\n",
    "\n",
    "# draw a bounding rectangle on the image starting at (x, y) and ending at (x+width, y+height)\n",
    "# use this to know what rectangle to extract in the cropping function above\n",
    "def draw_rectangle(image, x, y, width, height):\n",
    "    image_copy = image.copy()\n",
    "    cv2.rectangle(image_copy, pt1=(x, y), pt2=(x+width, y+height), color=(0, 255 ,0), thickness=5)\n",
    "    return image_copy\n",
    "\n",
    "# dilation\n",
    "def dilate(image):\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    return cv2.dilate(image, kernel, iterations = 1)\n",
    "    \n",
    "# erosion\n",
    "def erode(image):\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    return cv2.erode(image, kernel, iterations = 1)\n",
    "\n",
    "# opening - erosion followed by dilation\n",
    "def opening(image):\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    return cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "# canny edge detection\n",
    "def canny(image):\n",
    "    return cv2.Canny(image, 100, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deskew image based on skew angle found by package deskew\n",
    "from deskew import determine_skew\n",
    "# import math\n",
    "# import cv2\n",
    "\n",
    "def deskew(image):\n",
    "    def _rotate(image, angle):\n",
    "        old_width, old_height = image.shape[:2]\n",
    "        angle_radian = math.radians(angle)\n",
    "        width = abs(np.sin(angle_radian) * old_height) + abs(np.cos(angle_radian) * old_width)\n",
    "        height = abs(np.sin(angle_radian) * old_width) + abs(np.cos(angle_radian) * old_height)\n",
    "\n",
    "        image_center = tuple(np.array(image.shape[1::-1]) / 2)\n",
    "        rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n",
    "        rot_mat[1, 2] += (width - old_width) / 2\n",
    "        rot_mat[0, 2] += (height - old_height) / 2\n",
    "        return cv2.warpAffine(image, rot_mat, (int(round(height)), int(round(width))))\n",
    "    \n",
    "    angle = determine_skew(image)\n",
    "    return _rotate(image, angle)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test processing on some images\n",
    "Before running the recipe, you can explore what image processing do to your images and their text extraction.\n",
    "First we get the folder object and the filenames of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = dataiku.Folder(input_folder_id)\n",
    "input_filenames = input_folder.list_paths_in_partition()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select index of image on which you want to test processing\n",
    "Here you can print the filenames and their corresponding indexes so you can choose some specific images to try some processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, filename in enumerate(input_filenames):\n",
    "    print(\"Index: %s => Filename: %s\" % (idx, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we read the image into a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image_from_index(test_index):\n",
    "    test_file = input_filenames[test_index]\n",
    "    with input_folder.get_download_stream(test_file) as stream:\n",
    "        img_bytes = stream.read()\n",
    "    return np.array(Image.open(BytesIO(img_bytes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing the image processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "def display_images_before_after(raw_image, processed_image):\n",
    "    fig, ax = plt.subplots(1,2, figsize=(50,100))\n",
    "    ax[0].axis('off')\n",
    "    ax[1].axis('off')\n",
    "    ax[0].imshow(raw_image, cmap='Greys_r')\n",
    "    ax[1].imshow(processed_image, cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can apply multiple processing functions on 'raw_image' to get a 'processed_image'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_processing(img):\n",
    "    # add the right functions here\n",
    "    \n",
    "    # img = blurring(img)\n",
    "    # img = thresholding(img)\n",
    "    # img = resizing(img)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can visualize side by side the 'before' and 'after' processing using a test image index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_index = 5\n",
    "raw_image = read_image_from_index(test_index)\n",
    "processed_image = test_processing(raw_image)\n",
    "display_images_before_after(raw_image, processed_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyse the impact on text extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_extraction_before_after(raw_image, processed_image, lang='eng'):\n",
    "    raw_image_text = pytesseract.image_to_string(raw_image, lang=lang)\n",
    "    processed_image_text = pytesseract.image_to_string(processed_image, lang=lang)\n",
    "    \n",
    "    data = {'before':[raw_image_text, len(raw_image_text)],'after':[processed_image_text, len(processed_image_text)]}\n",
    "    df = pd.DataFrame.from_dict(data)\n",
    "    \n",
    "    pd.options.display.max_rows\n",
    "    pd.set_option('display.max_colwidth', -1)\n",
    "    \n",
    "    return df[['before','after']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see the extracted text 'before' and 'after' processing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_extraction_before_after(raw_image, processed_image, lang='eng')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run processing on all images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have found the processing functions to apply to the images, you can copy them in the Image Processing recipe form of the plugin.\n",
    "Then, the recipe will process with your functions all images in its input folder."
   ]
  }
 ],
 "metadata": {
  "creator": "admin",
  "customFields": {},
  "kernelspec": {
   "display_name": "Python (env tesseract_36)",
   "language": "python",
   "name": "py-dku-venv-tesseract_36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "tags": []
 },
 "nbformat": 4,
 "nbformat_minor": 1
}